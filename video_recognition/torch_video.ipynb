{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import av\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from timm.data import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "N_CLASSES = 4\n",
    "batch_size = 16\n",
    "root_dir = '../data/sibur_data/'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_frames = 32\n",
    "MIXUP_ALPHA = 0.2\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_video_augmentations(video, transform):\n",
    "    targets={'image': video[0]}\n",
    "    for i in range(1, video.shape[0]):\n",
    "        targets[f'image{i}'] = video[i]\n",
    "    transformed = transform(**targets)\n",
    "    transformed = np.concatenate(\n",
    "        [np.expand_dims(transformed['image'], axis=0)] \n",
    "        + [np.expand_dims(transformed[f'image{i}'], axis=0) for i in range(1, video.shape[0])]\n",
    "    )\n",
    "    return transformed\n",
    "\n",
    "def apply_video_augmentations_torch(video, transform):\n",
    "    targets={'image': video[0]}\n",
    "    for i in range(1, video.shape[0]):\n",
    "        targets[f'image{i}'] = video[i]\n",
    "    transformed = transform(**targets)\n",
    "    transformed = torch.cat(\n",
    "        [transformed['image'][None]] \n",
    "        + [transformed[f'image{i}'][None] for i in range(1, video.shape[0])]\n",
    "    )\n",
    "    transformed = transformed.permute(1, 0, 2, 3) # (batch,seq,ch,w,h) -> (batch,ch,seq,w,h)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "def sample_frame_indices(clip_len, seg_len):\n",
    "    start_idx, end_idx = 0, seg_len\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"bridge_down\", 1: \"bridge_up\", 2: \"no_action\", 3: \"train_in_out\"}\n",
    "label2id = {l:i for i, l in id2label.items()}\n",
    "labels = list(id2label.values())\n",
    "\n",
    "video_paths = list(Path(root_dir).rglob(\"*.mp4\"))\n",
    "targets = [vp.parent.name for vp in video_paths]\n",
    "train = pd.DataFrame({\n",
    "    \"video_path\": [v.as_posix() for v in video_paths],\n",
    "    \"label\": targets,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bridge_down     306\n",
       "bridge_up        75\n",
       "train_in_out     66\n",
       "no_action        49\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label_id'] = train.label.map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, _, _ = train_test_split(train, train['label'], test_size=0.1, random_state=42)\n",
    "\n",
    "# X_train.to_csv(\"train.csv\", index=False)\n",
    "# X_val.to_csv(\"test.csv\", index=False)\n",
    "# X_train = X_val = train\n",
    "\n",
    "X_train = pd.read_csv(\"train.csv\")\n",
    "X_val = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/and/miniforge3/envs/sibur/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "S3D(\n",
       "  (features): Sequential(\n",
       "    (0): TemporalSeparableConv(\n",
       "      (0): Conv3dNormActivation(\n",
       "        (0): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv3dNormActivation(\n",
       "        (0): Conv3d(64, 64, kernel_size=(7, 1, 1), stride=(2, 1, 1), padding=(3, 0, 0), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "    (2): Conv3dNormActivation(\n",
       "      (0): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): TemporalSeparableConv(\n",
       "      (0): Conv3dNormActivation(\n",
       "        (0): Conv3d(64, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv3dNormActivation(\n",
       "        (0): Conv3d(192, 192, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "        (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "    (5): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(192, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(96, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(192, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(16, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(32, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(192, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(128, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(192, 192, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(32, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(96, 96, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), dilation=1, ceil_mode=False)\n",
       "    (8): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(480, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(480, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(96, 208, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(208, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(208, 208, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(208, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(480, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(16, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(16, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(48, 48, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(480, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(512, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(112, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(112, 224, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(224, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(224, 224, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(224, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(24, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(24, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(24, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(24, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(112, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(144, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(144, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(288, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(288, 288, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(288, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(528, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(528, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(160, 320, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(528, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(32, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(528, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "    (14): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(832, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(832, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(160, 320, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(832, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(32, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): SepInceptionBlock3D(\n",
       "      (branch0): Conv3dNormActivation(\n",
       "        (0): Conv3d(832, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(832, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(192, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(384, 384, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv3dNormActivation(\n",
       "          (0): Conv3d(832, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): TemporalSeparableConv(\n",
       "          (0): Conv3dNormActivation(\n",
       "            (0): Conv3d(48, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv3dNormActivation(\n",
       "            (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): Conv3dNormActivation(\n",
       "          (0): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool3d(kernel_size=(2, 7, 7), stride=1, padding=0)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Conv3d(1024, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = models.video.mvit_v2_s(\"DEFAULT\") # .swin3d_t(\"DEFAULT\") #\n",
    "# model.head[1] = torch.nn.Linear(new_head[1].in_features, 4)\n",
    "# model.to(device)\n",
    "\n",
    "# model = models.video.swin3d_t(\"DEFAULT\")\n",
    "# model.head = torch.nn.Linear(model.head.in_features, N_CLASSES)\n",
    "# model.to(device)\n",
    "\n",
    "model = models.video.s3d(\"DEFAULT\")\n",
    "model.classifier[1] = torch.nn.Conv3d(model.classifier[1].in_channels, N_CLASSES, kernel_size=1, stride=1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.zeros((1, 3, 16, 224, 224)).cuda()\n",
    "# model(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/and/miniforge3/envs/sibur/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.CenterCrop(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Cutout(p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5\n",
    "    ),\n",
    "    A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.OneOf([  # One of blur or adding gauss noise\n",
    "        A.Blur(p=0.5),  # Blurs the image\n",
    "        A.GaussNoise(var_limit=5.0 / 255.0, p=0.50)  # Adds Gauss noise to image\n",
    "    ], p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.Normalize(OPENAI_CLIP_MEAN, OPENAI_CLIP_STD),\n",
    "    ToTensorV2(),\n",
    "], additional_targets={\n",
    "    f'image{i}': 'image'\n",
    "    for i in range(1, n_frames)\n",
    "})\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(232, 232),\n",
    "    A.CenterCrop(224, 224),\n",
    "    A.Normalize(OPENAI_CLIP_MEAN, OPENAI_CLIP_STD),\n",
    "    ToTensorV2(),\n",
    "], additional_targets={\n",
    "    f'image{i}': 'image'\n",
    "    for i in range(1, n_frames)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_transform(batch1, target1, batch2, target2, alpha=0.4):\n",
    "    lambda_ = np.random.beta(alpha, alpha)\n",
    "    batch = lambda_ * batch1 + (1 - lambda_) * batch2\n",
    "    target = lambda_ * target1 + (1 - lambda_) * target2\n",
    "    return batch, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, meta, stage, transform=None, n_frames=16):\n",
    "        self.meta = meta\n",
    "        self.transform = transform\n",
    "        self.n_frames = n_frames\n",
    "        self.stage = stage\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        file_path = self.meta['video_path'].iloc[idx]\n",
    "        container = av.open(file_path)\n",
    "        # indices = sample_frame_indices(clip_len=self.n_frames, seg_len=container.streams.video[0].frames)\n",
    "\n",
    "        seg_len=container.streams.video[0].frames\n",
    "        if self.stage == \"train\":\n",
    "            # mask indices\n",
    "            # в тесте 5/6 всех видео замаскированы\n",
    "            if np.random.random() < 0.8: \n",
    "                first_idxs = np.random.choice(range(0, seg_len), int(seg_len*0.75), replace=False).astype(int)\n",
    "                first_idxs.sort()\n",
    "            else:\n",
    "                first_idxs = np.arange(seg_len)\n",
    "            # n_frames indices\n",
    "            start_idx = np.random.randint(0, len(first_idxs) // 2)\n",
    "            end_idx = min(np.random.randint(len(first_idxs) // 2, len(first_idxs)) + self.n_frames, len(first_idxs))\n",
    "            indices = np.linspace(start_idx, end_idx, num=self.n_frames)\n",
    "            indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "            indices = first_idxs[indices]\n",
    "        else:\n",
    "            indices = sample_frame_indices(clip_len=self.n_frames, seg_len=container.streams.video[0].frames)\n",
    "\n",
    "        video = read_video_pyav(container, indices)\n",
    "                    \n",
    "        while video.shape[0] < self.n_frames:\n",
    "            video = np.vstack([video, video[-1:]])\n",
    "\n",
    "        if self.transform:\n",
    "            video = apply_video_augmentations_torch(video, self.transform)\n",
    "\n",
    "        target = np.zeros(N_CLASSES)\n",
    "        target[self.meta.iloc[idx].label_id] = 1\n",
    "            \n",
    "        return video, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset1 = ActionDataset(meta=X_train, stage=\"train\", transform=transform, n_frames=n_frames)\n",
    "train_dataloader1 = DataLoader(train_dataset1, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "train_dataset2 = ActionDataset(meta=X_train, stage=\"train\", transform=transform, n_frames=n_frames)\n",
    "train_dataloader2 = DataLoader(train_dataset2, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = ActionDataset(meta=X_val, stage=\"test\", transform=transform, n_frames=n_frames)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "lr = 1e-4 #5e-5\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "optimizer = optim.AdamW(model.parameters(), lr)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f9b302d6f64ff6adc0514d536ed2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213ec02ad58343ea836c9dda58715f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1119\n",
      "Valindation loss: 0.8531\n",
      "F1: 0.83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141d0519982f431cb02ba998f604a80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae5ab8ec3e14ac7869348805611c2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5027\n",
      "Valindation loss: 0.4944\n",
      "F1: 0.9407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3210e913d34256825762ec9c0947e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b0ec57df294cc9899a79bb838eabd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3918\n",
      "Valindation loss: 0.3724\n",
      "F1: 0.9726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb313c6f0e24d499103cdce65374878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc5d3067cc04fcab29acfab5db2286e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4261\n",
      "Valindation loss: 0.3468\n",
      "F1: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56036b36fa004934854780b387879298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6556fb6329b4eeb92ecf1f8f345e77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4255\n",
      "Valindation loss: 0.3963\n",
      "F1: 0.9577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4d1d61163d43339adbe8b5bae3fd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 5:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8088090ac1c3424b88ce2a93f2f68fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 5:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3782\n",
      "Valindation loss: 0.4026\n",
      "F1: 0.9487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38868eb5929346d18bad3a1513e806f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 6:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a4c816d0464508a03692ac01c367ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 6:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4034\n",
      "Valindation loss: 0.3896\n",
      "F1: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0701159d8c8b4b4fa1f719661bc993c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 7:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b93dd3c5a014a22accc54d646242683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 7:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4590\n",
      "Valindation loss: 0.4373\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()    \n",
    "\n",
    "    train_loss = []\n",
    "    for i, batch in enumerate(tqdm(zip(train_dataloader1, train_dataloader2), desc=f\"Epoch: {epoch}\", total=len(train_dataloader1))):\n",
    "        (batch1, target1), (batch2, target2) = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # mixup transform\n",
    "        batch, target = mixup_transform(batch1, target1, batch2, target2, MIXUP_ALPHA)\n",
    "        \n",
    "        with torch.autocast(\"cuda\"):\n",
    "            batch = batch.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            logits = model(batch)\n",
    "\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    model.eval()  \n",
    "\n",
    "    val_targets = []\n",
    "    val_preds = []\n",
    "    val_loss = 0\n",
    "    for i, (batch, target) in enumerate(tqdm(test_dataloader, desc=f\"Epoch: {epoch}\")):\n",
    "\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            batch = batch.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(batch)\n",
    "                loss = criterion(logits, target)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        val_targets.extend(target.argmax(1).cpu().tolist())\n",
    "        val_preds.extend(logits.argmax(1).cpu().tolist())\n",
    "\n",
    "    val_loss /= len(test_dataloader)\n",
    "    score = round(f1_score(val_targets, val_preds, average='macro'), 4)\n",
    "    print(f'Training loss: {np.mean(train_loss):.4f}')\n",
    "    print(f'Valindation loss: {val_loss:.4f}')\n",
    "    print('F1:', score)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model, \"best.pt\")\n",
    "    torch.save(model, \"last.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to onnx & openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"last.pt\")\n",
    "model.eval()\n",
    "\n",
    "file_path = X_val.iloc[0].video_path\n",
    "container = av.open(file_path)\n",
    "indices = sample_frame_indices(clip_len=n_frames, seg_len=container.streams.video[0].frames)\n",
    "video = read_video_pyav(container, indices)\n",
    "inputs = apply_video_augmentations_torch(video, transform).unsqueeze(0)\n",
    "\n",
    "outputs = model(inputs.to(device)).cpu()\n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnx_path = \"model.onnx\"\n",
    "\n",
    "model = model.float().cpu()\n",
    "model.eval()\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    inputs,\n",
    "    onnx_path,  # where to save the model\n",
    "    opset_version=14,  # the ONNX version to export the model to\n",
    "    input_names=[\"input\"],  # the model's input names\n",
    "    output_names=['output'],  # the model's output names\n",
    "    dynamic_axes={  # variable length axes\n",
    "        \"input\": {0: \"batch\", 1: \"channels\", 2: \"sequence\"},\n",
    "        \"output\": {0: \"batch\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import serialize\n",
    "from openvino.tools import mo\n",
    "\n",
    "ov_model = mo.convert_model('model.onnx', compress_to_fp16=True)\n",
    "serialize(ov_model, 'model.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_inputs = {\"input\": inputs.cpu().numpy()}\n",
    "\n",
    "# ort_session = ort.InferenceSession(\"model.onnx\")\n",
    "\n",
    "# # compute ONNX Runtime output prediction\n",
    "# ort_outs = ort_session.run(None, dummy_inputs)[0]\n",
    "\n",
    "# # compute pytorch model outputs\n",
    "# with torch.no_grad():\n",
    "#     model.cpu()\n",
    "#     torch_model_outs = model(inputs).numpy()\n",
    "#     model.cuda()\n",
    "\n",
    "# np.testing.assert_allclose(\n",
    "#     torch_model_outs,\n",
    "#     ort_outs,\n",
    "#     rtol=1e-03,\n",
    "#     atol=1e-05,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_val.to_csv(\"test.csv\", index=False)\n",
    "X_val = pd.read_csv(\"test.csv\")\n",
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc9fccdfe0849099a3ae1a2019ba69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import get_frames\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "test_videos_paths = [Path(p) for p in X_val.video_path.values][:]\n",
    "test_targets = X_val.label_id[:]\n",
    "test_targets_masked = [t for t in test_targets for _ in range(6)]\n",
    "\n",
    "clips = [\n",
    "    get_frames(vp)\n",
    "    for vp in tqdm(test_videos_paths[:])\n",
    "]\n",
    "\n",
    "masks = [\n",
    "    np.ones(len(c), dtype=bool)\n",
    "    for c in clips\n",
    "]\n",
    "\n",
    "new_masks = []\n",
    "for m in masks:\n",
    "    new_masks.append(m)\n",
    "    for _ in range(5):\n",
    "        new_m = m.copy()\n",
    "        new_m[np.random.choice(range(0, len(m)), int(len(m)*0.2), replace=False).astype(int)] = False\n",
    "        new_masks.append(new_m)\n",
    "\n",
    "masked_clips = []\n",
    "for i, c in enumerate(clips):\n",
    "    for m in new_masks[i*6:(i+1)*6]:\n",
    "        masked_clips.append(c[m])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onnx/openvino model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# from submit_transformer.predict import predict\n",
    "# from submit_videorec.predict_openvino import predict as predict_openvino\n",
    "from submit_videorec.predict_onnx import predict as predict_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f449bf1eb3c349c68ab6d5d9cab39e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m BUFFER \u001b[39m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[39m# 32 frames = 1.38 min\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# 16 frames = \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m preds \u001b[39m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     predict_onnx(clip, BUFFER)\n\u001b[1;32m      7\u001b[0m     \u001b[39mfor\u001b[39;00m clip \u001b[39min\u001b[39;00m tqdm(masked_clips)\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m      9\u001b[0m preds_ids \u001b[39m=\u001b[39m [label2id[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m preds]\n\u001b[1;32m     10\u001b[0m \u001b[39mround\u001b[39m(f1_score(test_targets_masked, preds_ids, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m BUFFER \u001b[39m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[39m# 32 frames = 1.38 min\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# 16 frames = \u001b[39;00m\n\u001b[1;32m      5\u001b[0m preds \u001b[39m=\u001b[39m [\n\u001b[0;32m----> 6\u001b[0m     predict_onnx(clip, BUFFER)\n\u001b[1;32m      7\u001b[0m     \u001b[39mfor\u001b[39;00m clip \u001b[39min\u001b[39;00m tqdm(masked_clips)\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m      9\u001b[0m preds_ids \u001b[39m=\u001b[39m [label2id[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m preds]\n\u001b[1;32m     10\u001b[0m \u001b[39mround\u001b[39m(f1_score(test_targets_masked, preds_ids, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m4\u001b[39m)\n",
      "File \u001b[0;32m~/projects/hacks/sibur_2023/video_recognition/../submit_videorec/predict_onnx.py:59\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(clip, BUFFER)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Вычислить класс для этого клипа. Эта функция должна возвращать *имя* класса.\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m inputs \u001b[39m=\u001b[39m preprocess(clip, n_frames\u001b[39m=\u001b[39mN_FRAMES)\n\u001b[0;32m---> 59\u001b[0m predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mrun(\u001b[39mNone\u001b[39;49;00m, inputs)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m id2label[predict]\n",
      "File \u001b[0;32m~/miniforge3/envs/sibur/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:217\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    215\u001b[0m     output_names \u001b[39m=\u001b[39m [output\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_meta]\n\u001b[1;32m    216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(output_names, input_feed, run_options)\n\u001b[1;32m    218\u001b[0m \u001b[39mexcept\u001b[39;00m C\u001b[39m.\u001b[39mEPFail \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    219\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BUFFER = {}\n",
    "# 32 frames = 1.38 min\n",
    "# 16 frames = \n",
    "\n",
    "preds = [\n",
    "    predict_onnx(clip, BUFFER)\n",
    "    for clip in tqdm(masked_clips)\n",
    "]\n",
    "preds_ids = [label2id[i] for i in preds]\n",
    "round(f1_score(test_targets_masked, preds_ids, average='macro'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4165ba3308814e9aa4080901e5920200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER = {}\n",
    "\n",
    "preds = [\n",
    "    predict_openvino(clip, BUFFER)\n",
    "    for clip in tqdm(masked_clips)\n",
    "]\n",
    "preds_ids = [label2id[i] for i in preds]\n",
    "round(f1_score(test_targets_masked, preds_ids, average='macro'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.748 window=2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bb463029454e999b03da66dedffd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torch.load(\"best.pt\", map_location=\"cpu\")\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "preds_torch = []\n",
    "for clip in tqdm(masked_clips):\n",
    "    # start_idx, end_idx = 0, len(clip)\n",
    "    # indices = np.linspace(start_idx, end_idx, num=n_frames)\n",
    "    # indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int32)\n",
    "    step = 2\n",
    "    s = 0\n",
    "    e = (s + n_frames) * step\n",
    "    clip = clip[s:e:step]\n",
    "    clip = apply_video_augmentations_torch(clip, transform).unsqueeze(0)\n",
    "\n",
    "    with torch.autocast(\"cuda\"):\n",
    "        clip = clip.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(clip).cpu()\n",
    "        preds_torch.append(logits.argmax(1)[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9142"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(f1_score(test_targets_masked, preds_torch, average='macro'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, j in zip(preds_torch, test_targets):\n",
    "#     print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sibur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
